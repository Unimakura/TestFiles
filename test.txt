// AudioRecorderPlugin.java
package com.example.audiorecorder;

import android.media.AudioFormat;
import android.media.AudioRecord;
import android.media.MediaRecorder;
import android.util.Log;

public class AudioRecorderPlugin {
    private static final String TAG = "AudioRecorderPlugin";
    private static final int SAMPLE_RATE = 44100;
    private static final int CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO;
    private static final int AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT;

    private AudioRecord audioRecord;
    private boolean isRecording = false;
    private int bufferSize;

    public boolean initializeAudioRecorder() {
        bufferSize = AudioRecord.getMinBufferSize(SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT);
        if (bufferSize == AudioRecord.ERROR || bufferSize == AudioRecord.ERROR_BAD_VALUE) {
            Log.e(TAG, "Invalid buffer size");
            return false;
        }

        audioRecord = new AudioRecord(MediaRecorder.AudioSource.VOICE_COMMUNICATION,
                SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT, bufferSize);

        if (audioRecord.getState() != AudioRecord.STATE_INITIALIZED) {
            Log.e(TAG, "AudioRecord initialization failed");
            return false;
        }

        return true;
    }

    public void startRecording() {
        if (audioRecord != null && !isRecording) {
            audioRecord.startRecording();
            isRecording = true;
            Log.d(TAG, "Recording started");
        }
    }

    public void stopRecording() {
        if (audioRecord != null && isRecording) {
            audioRecord.stop();
            isRecording = false;
            Log.d(TAG, "Recording stopped");
        }
    }

    public int readAudioData(short[] audioBuffer) {
        if (audioRecord != null && isRecording) {
            return audioRecord.read(audioBuffer, 0, audioBuffer.length);
        }
        return 0;
    }

    public void release() {
        if (audioRecord != null) {
            audioRecord.release();
            audioRecord = null;
            isRecording = false;
            Log.d(TAG, "AudioRecord released");
        }
    }

    public int getAudioSessionId() {
        return audioRecord != null ? audioRecord.getAudioSessionId() : -1;
    }
}

// AudioRecorderInterface.cs
using UnityEngine;
using System.Runtime.InteropServices;

public class AudioRecorderInterface : MonoBehaviour
{
    private const string PluginName = "com.example.audiorecorder.AudioRecorderPlugin";
    private static AndroidJavaObject plugin;

    private static AndroidJavaObject Plugin
    {
        get
        {
            if (plugin == null)
            {
                plugin = new AndroidJavaObject(PluginName);
            }
            return plugin;
        }
    }

    public static bool InitializeAudioRecorder()
    {
        if (Application.platform == RuntimePlatform.Android)
        {
            return Plugin.Call<bool>("initializeAudioRecorder");
        }
        return false;
    }

    public static void StartRecording()
    {
        if (Application.platform == RuntimePlatform.Android)
        {
            Plugin.Call("startRecording");
        }
    }

    public static void StopRecording()
    {
        if (Application.platform == RuntimePlatform.Android)
        {
            Plugin.Call("stopRecording");
        }
    }

    public static int ReadAudioData(short[] buffer)
    {
        if (Application.platform == RuntimePlatform.Android)
        {
            return Plugin.Call<int>("readAudioData", buffer);
        }
        return 0;
    }

    public static void Release()
    {
        if (Application.platform == RuntimePlatform.Android)
        {
            Plugin.Call("release");
        }
    }

    public static int GetAudioSessionId()
    {
        if (Application.platform == RuntimePlatform.Android)
        {
            return Plugin.Call<int>("getAudioSessionId");
        }
        return -1;
    }
}

// AudioManager.cs
using UnityEngine;
using System.Collections;

public class AudioManager : MonoBehaviour
{
    private AudioSource audioSource;
    private short[] audioBuffer;
    private const int BufferSize = 4096;

    void Start()
    {
        audioSource = GetComponent<AudioSource>();
        audioBuffer = new short[BufferSize];

        StartCoroutine(InitializeAndStartRecording());
    }

    IEnumerator InitializeAndStartRecording()
    {
        // Request microphone permission
        if (!Permission.HasUserAuthorizedPermission(Permission.Microphone))
        {
            Permission.RequestUserPermission(Permission.Microphone);
            yield return new WaitUntil(() => Permission.HasUserAuthorizedPermission(Permission.Microphone));
        }

        bool initialized = AudioRecorderInterface.InitializeAudioRecorder();
        if (initialized)
        {
            AudioRecorderInterface.StartRecording();
            StartCoroutine(ProcessAudio());
        }
        else
        {
            Debug.LogError("Failed to initialize audio recorder");
        }
    }

    IEnumerator ProcessAudio()
    {
        while (true)
        {
            int samplesRead = AudioRecorderInterface.ReadAudioData(audioBuffer);
            if (samplesRead > 0)
            {
                // Convert short array to float array
                float[] floatBuffer = new float[samplesRead];
                for (int i = 0; i < samplesRead; i++)
                {
                    floatBuffer[i] = audioBuffer[i] / 32768f;
                }

                // Create AudioClip and set data
                AudioClip clip = AudioClip.Create("RecordedAudio", samplesRead, 1, 44100, false);
                clip.SetData(floatBuffer, 0);

                // Play the audio
                audioSource.clip = clip;
                audioSource.Play();
            }
            yield return null;
        }
    }

    void OnDestroy()
    {
        AudioRecorderInterface.StopRecording();
        AudioRecorderInterface.Release();
    }
}
